# Grounding SAM 2 動画物体追跡アプリケーション

🎯 Grounding SAM 2技術を使用した動画内の物体検出、セグメンテーション、および追跡のためのStreamlitベースアプリケーション
<img width="1211" height="296" alt="image" src="https://github.com/user-attachments/assets/e2c5bc48-1e9d-417f-aa84-50ba15d91d4e" />


## 概要

このアプリケーションは、Grounding SAM 2（Segment Anything Model 2）の力と自然言語による物体検出を組み合わせ、動画解析のための直感的なインターフェースを提供します。ユーザーは動画をアップロードし、シンプルなテキスト記述を使用して追跡する物体を指定できます。

## 主な機能

- 📹 **動画アップロード**: 複数の動画形式をサポート（MP4、AVI、MOV、MKV）
- 🔍 **テキストベース物体検出**: 自然言語での物体記述
- 🎯 **精密セグメンテーション**: SAM 2による正確な物体境界の取得
- 📊 **リアルタイム追跡**: 動画フレーム間での物体追跡
- 📈 **インタラクティブ可視化**: Plotlyによるチャートと分析
- 🖥️ **ユーザーフレンドリー**: 直感的なStreamlit Webインターフェース

## 技術アーキテクチャ

### Grounding SAM 2 技術

**Grounding SAM 2**は、視覚言語理解における重要な進歩を表し、以下を組み合わせています：

#### モデルアーキテクチャ

1. **GroundingDINO**: 
   - テキスト条件付き物体検出モデル
   - 自然言語クエリを視覚物体検出に変換
   - クロスモーダル注意機構を持つTransformerアーキテクチャを使用
   - テキストで記述された物体のゼロショット検出を可能にする

2. **Segment Anything Model 2 (SAM 2)**:
   - Meta AIによる高度なセグメンテーションモデル
   - ピクセル完璧な物体境界を提供
   - 様々なプロンプトタイプをサポート（点、ボックス、マスク）
   - 動画の時間的一貫性に最適化

3. **動画追跡パイプライン**:
   - 検出とセグメンテーションを組み合わせた堅牢な追跡
   - フレーム間での物体アイデンティティを維持
   - オクルージョンと再識別を処理

#### 先進的な機能

- **クロスモーダル理解**: 自然言語とコンピュータビジョンの橋渡し
- **ゼロショット能力**: 特定の訓練なしに物体を検出
- **時間的一貫性**: 動画シーケンス全体での追跡維持
- **高品質セグメンテーション**: 物体境界のピクセルレベル精度
- **リアルタイム処理**: 効率的な動画解析に最適化

### 技術実装

```
テキストプロンプト → GroundingDINO → 物体検出 → SAM 2 → セグメンテーション → 追跡
```

#### 主要コンポーネント:

1. **テキストエンコーダー**: 自然言語記述を処理
2. **ビジョンエンコーダー**: 動画フレームから視覚特徴を抽出
3. **クロスモーダル融合**: テキストと視覚表現を整合
4. **物体検出器**: テキストクエリに基づく物体の位置特定
5. **セグメンテーションモデル**: 精密な物体マスクを生成
6. **トラッカー**: フレーム間での物体アイデンティティを維持

## インストール

### 必要な環境

- Python 3.8以上
- CUDA対応GPU（推奨）
- UVパッケージマネージャー

### セットアップ

1. リポジトリをクローン:
```bash
git clone <repository-url>
cd grounding_sam2_app
```

2. UVを使用して依存関係をインストール:
```bash
uv init
uv add streamlit plotly opencv-python pillow torch torchvision numpy pandas matplotlib seaborn transformers supervision ultralytics segment-anything
```

3. アプリケーションを実行:
```bash
uv run streamlit run main.py
```

## 使用方法

### 基本ワークフロー

1. **アプリケーションを起動**:
   ```bash
   uv run streamlit run main.py
   ```

2. **動画をアップロード**:
   - "Browse files"をクリックして動画をアップロード
   - 対応形式: MP4、AVI、MOV、MKV

3. **追跡する物体を指定**:
   - サイドバーにテキスト記述を入力
   - 例: "person"（人）、"car"（車）、"dog"（犬）、"red car"（赤い車）、"walking person"（歩いている人）

4. **動画を処理**:
   - "🚀 Process Video"ボタンをクリック
   - 処理完了まで待機

5. **結果を確認**:
   - 検出統計を示すインタラクティブチャート
   - フレームごとの追跡結果
   - 処理パイプラインの可視化

### 高度な機能

- **パイプライン可視化**: 完全な処理ワークフローの表示
- **検出分析**: 信頼度分布と時間的分析
- **サンプル動画**: デモ用の事前設定されたテストケース

## モデル詳細

### GroundingDINO

- **アーキテクチャ**: Transformerベースの検出モデル
- **学習**: 大規模視覚言語データセット
- **能力**: オープン語彙物体検出
- **性能**: 多様な物体カテゴリで高精度

### SAM 2

- **モデルサイズ**: 複数のバリアント（Base、Large、Huge）
- **学習データ**: SA-1Bデータセット（10億以上のマスク）
- **セグメンテーション品質**: 最先端のマスク精度
- **動画サポート**: フレーム間の時間的一貫性

## パフォーマンス考慮事項

### ハードウェア要件

- **GPU**: NVIDIA GPU（VRAM 8GB以上推奨）
- **CPU**: 動画処理用マルチコアプロセッサー
- **RAM**: 大きな動画ファイル用に16GB以上
- **ストレージ**: 動画I/O用にSSD推奨

### 最適化のヒント

- より高速な処理のために低解像度動画を使用
- リアルタイム分析のために動画長を制限
- 検出信頼度閾値を調整
- 利用可能な場合はGPUアクセラレーションを有効化

## 使用例

### プロフェッショナル用途

- **セキュリティ・監視**: 特定の個人や物体の追跡
- **スポーツ分析**: 選手の動きと戦略の分析
- **野生動物監視**: 自然生息地での動物追跡
- **産業検査**: 設備とプロセスの監視

### 研究用途

- **コンピュータビジョン研究**: 追跡アルゴリズムの評価
- **行動研究**: 物体間相互作用の分析
- **データセット作成**: 注釈付き動画データセットの生成
- **ベンチマークテスト**: 検出モデルの比較

## 技術仕様

### サポートされる動画コーデック

- H.264/AVC
- H.265/HEVC
- VP9
- AV1（実験的）

### 処理能力

- **フレームレート**: 最大30 FPS
- **解像度**: 最大4K（4096×2160）
- **時間**: 理論的制限なし（メモリ依存）
- **バッチ処理**: 連続した複数の動画

## API リファレンス

### コアクラス

#### `GroundingSAM2Pipeline`

動画解析のためのメイン処理パイプライン。

**メソッド:**
- `load_models()`: 検出とセグメンテーションモデルを初期化
- `detect_objects_in_frame(frame, text_prompt)`: 単一フレームで物体を検出
- `process_video(video_path, text_prompt)`: 動画全体を処理

### 可視化関数

#### `visualize_tracking_results(frames_data)`

追跡分析用のインタラクティブチャートを生成。

## コントリビューション

1. リポジトリをフォーク
2. 機能ブランチを作成
3. 変更を加える
4. 新機能にテストを追加
5. プルリクエストを送信

## ライセンス

このプロジェクトはMITライセンスの下でライセンスされています - 詳細はLICENSEファイルを参照してください。

## 謝辞

- **Meta AI**: Segment Anything Model 2の提供
- **IDEA Research**: GroundingDINOの実装
- **Ultralytics**: YOLO統合
- **Streamlit**: Webアプリケーションフレームワーク

## 参考文献

- [Grounding SAM 2 リポジトリ](https://github.com/IDEA-Research/Grounded-SAM-2)
- [SAM 2 論文](https://arxiv.org/abs/2401.12741)
- [GroundingDINO 論文](https://arxiv.org/abs/2303.05499)
- [Segment Anything プロジェクト](https://segment-anything.com/)

## サポート

問題や質問については:
- [Issues](https://github.com/your-repo/issues) ページを確認
- ドキュメントを確認
- メンテナーに連絡

---

❤️ Streamlit と Grounding SAM 2 を使用して構築


